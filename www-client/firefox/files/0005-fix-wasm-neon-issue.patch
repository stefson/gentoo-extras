# HG changeset patch
# User Lars T Hansen <lhansen@mozilla.com>
# Date 1628235677 0
# Node ID baa2e3ee94bcae936d7d3acd5bb251ac6477b078
# Parent  48adeca98451cdb2e6810faf0ab0c3e741ff2a24
Bug 1587757 - Avoid signal handling for unaligned accesses. r=jseward

On ARM, the VLDR and VSTR instructions can't handle unaligned
accesses, instead they will generally trap with a SIGBUS.  Some time
ago I added code to handle the trap and emulate the instructions in
the trap handler.  This emulation is brittle in the sense that it
depends on information about kernel data structures, and that
information is not always available.  So we need to handle this
differently, as follows.

This patch removes the SIGBUS handling and the load/store emulation,
and instead uses other instructions than VLDR/VSTR to handle FP loads
and stores.

On NEON-equipped systems (on almost all ARMv7 systems and on all ARMv8
systems), use the NEON VLD1 and VST1 instructions - they can deal with
unaligned data just fine.

On non-NEON-equipped systems, use a fallback path via integer load and
store, moving integer data to and from the FP register file.

Both paths depend on us seeing no unaligned traps, ie, either
SCTRL.A=0, or the kernel handling alignment traps when SCTRL.A=1.  But
we've long since assumed that unaligned integer loads and stores will
Just Work under exactly those conditions, so this is going to have to
count as good enough.  (And it's what V8 did, last I looked.)

As our assembler, simulator, and disassembler don't currently support
NEON much at all, I've had to add various support for VLD1/VST1, both
new variants and a drive-by fix to an existing VLD1 variant that
didn't handle wasm traps.

For code that does not use unaligned FP accesses, the performance of
the new NEON code should be the same as the old code, while the new
non-NEON code might be a hair slower (this is OK since almost all
systems have NEON).  For code that does use unaligned FP accesses,
performance should be much better, as we avoid the signal handler.

Differential Revision: https://phabricator.services.mozilla.com/D121833

diff --git a/js/src/jit/arm/Architecture-arm.cpp b/js/src/jit/arm/Architecture-arm.cpp
--- a/js/src/jit/arm/Architecture-arm.cpp
+++ b/js/src/jit/arm/Architecture-arm.cpp
@@ -323,16 +323,21 @@ void InitARMFlags() {
   return;
 }
 
 uint32_t GetARMFlags() {
   MOZ_ASSERT(armHwCapFlags != HWCAP_UNINITIALIZED);
   return armHwCapFlags;
 }
 
+bool HasNEON() {
+  MOZ_ASSERT(armHwCapFlags != HWCAP_UNINITIALIZED);
+  return armHwCapFlags & HWCAP_NEON;
+}
+
 bool HasARMv7() {
   MOZ_ASSERT(armHwCapFlags != HWCAP_UNINITIALIZED);
   return armHwCapFlags & HWCAP_ARMv7;
 }
 
 bool HasMOVWT() {
   MOZ_ASSERT(armHwCapFlags != HWCAP_UNINITIALIZED);
   return armHwCapFlags & HWCAP_ARMv7;
diff --git a/js/src/jit/arm/Architecture-arm.h b/js/src/jit/arm/Architecture-arm.h
--- a/js/src/jit/arm/Architecture-arm.h
+++ b/js/src/jit/arm/Architecture-arm.h
@@ -645,16 +645,17 @@ uint32_t GetARMFlags();
 bool HasARMv7();
 bool HasMOVWT();
 bool HasLDSTREXBHD();  // {LD,ST}REX{B,H,D}
 bool HasDMBDSBISB();   // DMB, DSB, and ISB
 bool HasVFPv3();
 bool HasVFP();
 bool Has32DP();
 bool HasIDIV();
+bool HasNEON();
 
 extern volatile uint32_t armHwCapFlags;
 
 // Not part of the HWCAP flag, but we need to know these and these bits are not
 // used. Define these here so that their use can be inlined by the simulator.
 
 // A bit to flag when signaled alignment faults are to be fixed up.
 #define HWCAP_FIXUP_FAULT (1 << 24)
diff --git a/js/src/jit/arm/Assembler-arm.cpp b/js/src/jit/arm/Assembler-arm.cpp
--- a/js/src/jit/arm/Assembler-arm.cpp
+++ b/js/src/jit/arm/Assembler-arm.cpp
@@ -2113,16 +2113,40 @@ BufferOffset Assembler::as_vdtm(LoadStor
   if (vd.isDouble()) {
     length *= 2;
   }
 
   return writeVFPInst(sz, dtmLoadStore | RN(rn) | VD(vd) | length | dtmMode |
                               dtmUpdate | dtmCond);
 }
 
+BufferOffset Assembler::as_vldr_unaligned(VFPRegister vd, Register rn) {
+  MOZ_ASSERT(HasNEON());
+  if (vd.isDouble()) {
+    // vld1 (multiple single elements) with align=0, size=3, numregs=1
+    return writeInst(0xF42007CF | RN(rn) | VD(vd));
+  }
+  // vld1 (single element to single lane) with index=0, size=2
+  MOZ_ASSERT(vd.isFloat());
+  uint32_t index = (vd.code() & 1);
+  return writeInst(0xF4A0080F | RN(rn) | VD(vd.asDouble()) | (index << 5));
+}
+
+BufferOffset Assembler::as_vstr_unaligned(VFPRegister vd, Register rn) {
+  MOZ_ASSERT(HasNEON());
+  if (vd.isDouble()) {
+    // vst1 (multiple single elements) with align=0, size=3, numregs=1
+    return writeInst(0xF40007CF | RN(rn) | VD(vd));
+  }
+  // vst1 (single element from one lane) with index=0, size=2
+  MOZ_ASSERT(vd.isFloat());
+  uint32_t index = (vd.code() & 1);
+  return writeInst(0xF480080F | RN(rn) | VD(vd.asDouble()) | (index << 5));
+}
+
 BufferOffset Assembler::as_vimm(VFPRegister vd, VFPImm imm, Condition c) {
   MOZ_ASSERT(imm.isValid());
   vfp_size sz = vd.isDouble() ? IsDouble : IsSingle;
   return writeVFPInst(sz, c | imm.encode() | VD(vd) | 0x02B00000);
 }
 
 BufferOffset Assembler::as_vmrs(Register r, Condition c) {
   return writeInst(c | 0x0ef10a10 | RT(r));
diff --git a/js/src/jit/arm/Assembler-arm.h b/js/src/jit/arm/Assembler-arm.h
--- a/js/src/jit/arm/Assembler-arm.h
+++ b/js/src/jit/arm/Assembler-arm.h
@@ -1640,16 +1640,22 @@ class Assembler : public AssemblerShared
                             uint32_t* dest);
 
   // VFP's ldm/stm work differently from the standard arm ones. You can only
   // transfer a range.
 
   BufferOffset as_vdtm(LoadStore st, Register rn, VFPRegister vd, int length,
                        /* also has update conditions */ Condition c = Always);
 
+  // vldr/vstr variants that handle unaligned accesses.  These encode as NEON
+  // single-element instructions and can only be used if NEON is available.
+  // Here, vd must be tagged as a float or double register.
+  BufferOffset as_vldr_unaligned(VFPRegister vd, Register rn);
+  BufferOffset as_vstr_unaligned(VFPRegister vd, Register rn);
+
   BufferOffset as_vimm(VFPRegister vd, VFPImm imm, Condition c = Always);
 
   BufferOffset as_vmrs(Register r, Condition c = Always);
   BufferOffset as_vmsr(Register r, Condition c = Always);
 
   // Label operations.
   bool nextLink(BufferOffset b, BufferOffset* next);
   void bind(Label* label, BufferOffset boff = BufferOffset());
diff --git a/js/src/jit/arm/MacroAssembler-arm.cpp b/js/src/jit/arm/MacroAssembler-arm.cpp
--- a/js/src/jit/arm/MacroAssembler-arm.cpp
+++ b/js/src/jit/arm/MacroAssembler-arm.cpp
@@ -6153,21 +6153,47 @@ void MacroAssemblerARM::wasmLoadImpl(con
         ma_mov(Imm32(0), out64.high);
       }
     }
   } else {
     bool isFloat = output.isFloat();
     if (isFloat) {
       MOZ_ASSERT((byteSize == 4) == output.fpu().isSingle());
       ScratchRegisterScope scratch(asMasm());
+      FloatRegister dest = output.fpu();
       ma_add(memoryBase, ptr, scratch);
 
-      // See HandleUnalignedTrap() in WasmSignalHandler.cpp.  We depend on this
-      // being a single, unconditional VLDR with a base pointer other than PC.
-      load = ma_vldr(Operand(Address(scratch, 0)).toVFPAddr(), output.fpu());
+      // FP loads can't use VLDR as that has stringent alignment checks and will
+      // SIGBUS on unaligned accesses.  Choose a different strategy depending on
+      // the available hardware. We don't gate Wasm on the presence of NEON.
+      if (HasNEON()) {
+        // NEON available: The VLD1 multiple-single-elements variant will only
+        // trap if SCTRL.A==1, but we already assume (for integer accesses) that
+        // the hardware/OS handles that transparently.
+        load = as_vldr_unaligned(dest, scratch);
+      } else {
+        // NEON not available: Load to GPR scratch, move to FPR destination.  We
+        // don't have adjacent scratches for the f64, so use individual LDRs,
+        // not LDRD.
+        SecondScratchRegisterScope scratch2(asMasm());
+        if (byteSize == 4) {
+          load = as_dtr(IsLoad, 32, Offset, scratch2,
+                        DTRAddr(scratch, DtrOffImm(0)), Always);
+          as_vxfer(scratch2, InvalidReg, VFPRegister(dest), CoreToFloat,
+                   Always);
+        } else {
+          // The trap information is associated with the load of the high word,
+          // which must be done first.
+          load = as_dtr(IsLoad, 32, Offset, scratch2,
+                        DTRAddr(scratch, DtrOffImm(4)), Always);
+          as_dtr(IsLoad, 32, Offset, scratch, DTRAddr(scratch, DtrOffImm(0)),
+                 Always);
+          as_vxfer(scratch, scratch2, VFPRegister(dest), CoreToFloat, Always);
+        }
+      }
       append(access, load.getOffset());
     } else {
       load = ma_dataTransferN(IsLoad, byteSize * 8, isSigned, memoryBase, ptr,
                               output.gpr());
       append(access, load.getOffset());
     }
   }
 
@@ -6220,19 +6246,42 @@ void MacroAssemblerARM::wasmStoreImpl(co
     append(access, store.getOffset());
   } else {
     if (value.isFloat()) {
       ScratchRegisterScope scratch(asMasm());
       FloatRegister val = value.fpu();
       MOZ_ASSERT((byteSize == 4) == val.isSingle());
       ma_add(memoryBase, ptr, scratch);
 
-      // See HandleUnalignedTrap() in WasmSignalHandler.cpp.  We depend on this
-      // being a single, unconditional VLDR with a base pointer other than PC.
-      store = ma_vstr(val, Operand(Address(scratch, 0)).toVFPAddr());
+      // See comments above at wasmLoadImpl for more about this logic.
+      if (HasNEON()) {
+        store = as_vstr_unaligned(val, scratch);
+      } else {
+        // NEON not available: Move FPR to GPR scratch, store GPR.  We have only
+        // one scratch to hold the value, so for f64 we must do two separate
+        // moves.  That's OK - this is really a corner case.  If we really cared
+        // we would pass in a temp to avoid the second move.
+        SecondScratchRegisterScope scratch2(asMasm());
+        if (byteSize == 4) {
+          as_vxfer(scratch2, InvalidReg, VFPRegister(val), FloatToCore, Always);
+          store = as_dtr(IsStore, 32, Offset, scratch2,
+                         DTRAddr(scratch, DtrOffImm(0)), Always);
+        } else {
+          // The trap information is associated with the store of the high word,
+          // which must be done first.
+          as_vxfer(scratch2, InvalidReg, VFPRegister(val).singleOverlay(1),
+                   FloatToCore, Always);
+          store = as_dtr(IsStore, 32, Offset, scratch2,
+                         DTRAddr(scratch, DtrOffImm(4)), Always);
+          as_vxfer(scratch2, InvalidReg, VFPRegister(val).singleOverlay(0),
+                   FloatToCore, Always);
+          as_dtr(IsStore, 32, Offset, scratch2, DTRAddr(scratch, DtrOffImm(0)),
+                 Always);
+        }
+      }
       append(access, store.getOffset());
     } else {
       bool isSigned = type == Scalar::Uint32 ||
                       type == Scalar::Int32;  // see AsmJSStoreHeap;
       Register val = value.gpr();
 
       store = ma_dataTransferN(IsStore, 8 * byteSize /* bits */, isSigned,
                                memoryBase, ptr, val);
diff --git a/js/src/jit/arm/Simulator-arm.cpp b/js/src/jit/arm/Simulator-arm.cpp
--- a/js/src/jit/arm/Simulator-arm.cpp
+++ b/js/src/jit/arm/Simulator-arm.cpp
@@ -4797,18 +4797,22 @@ void Simulator::decodeSpecialCondition(S
             break;
         }
         int r = 0;
         while (r < regs) {
           uint32_t data[2];
           get_d_register(Vd + r, data);
           // TODO: We should AllowUnaligned here only if the alignment attribute
           // of the instruction calls for default alignment.
-          writeW(address, data[0], instr, AllowUnaligned);
-          writeW(address + 4, data[1], instr, AllowUnaligned);
+          //
+          // Use writeQ to get handling of traps right.  (The spec says to
+          // perform two individual word writes, but let's not worry about
+          // that.)
+          writeQ(address, (uint64_t(data[1]) << 32) | uint64_t(data[0]), instr,
+                 AllowUnaligned);
           address += 8;
           r++;
         }
         if (Rm != 15) {
           if (Rm == 13) {
             set_register(Rn, address);
           } else {
             set_register(Rn, get_register(Rn) + get_register(Rm));
@@ -4839,33 +4843,80 @@ void Simulator::decodeSpecialCondition(S
             MOZ_CRASH();
             break;
         }
         int r = 0;
         while (r < regs) {
           uint32_t data[2];
           // TODO: We should AllowUnaligned here only if the alignment attribute
           // of the instruction calls for default alignment.
-          data[0] = readW(address, instr, AllowUnaligned);
-          data[1] = readW(address + 4, instr, AllowUnaligned);
+          //
+          // Use readQ to get handling of traps right.  (The spec says to
+          // perform two individual word reads, but let's not worry about that.)
+          uint64_t tmp = readQ(address, instr, AllowUnaligned);
+          data[0] = tmp;
+          data[1] = tmp >> 32;
           set_d_register(Vd + r, data);
           address += 8;
           r++;
         }
         if (Rm != 15) {
           if (Rm == 13) {
             set_register(Rn, address);
           } else {
             set_register(Rn, get_register(Rn) + get_register(Rm));
           }
         }
       } else {
         MOZ_CRASH();
       }
       break;
+    case 9:
+      if (instr->bits(9, 8) == 0) {
+        int Vd = (instr->bit(22) << 4) | instr->vdValue();
+        int Rn = instr->vnValue();
+        int size = instr->bits(11, 10);
+        int Rm = instr->vmValue();
+        int index = instr->bits(7, 5);
+        int align = instr->bit(4);
+        int32_t address = get_register(Rn);
+        if (size != 2 || align) {
+          MOZ_CRASH("NYI");
+        }
+        if (index > 1) {
+          Vd++;
+          index -= 2;
+        }
+        uint32_t data[2];
+        get_d_register(Vd, data);
+        switch (instr->bits(21, 20)) {
+          case 0:
+            // vst1 single element from one lane
+            writeW(address, data[index], instr, AllowUnaligned);
+            break;
+          case 2:
+            // vld1 single element to one lane
+            data[index] = readW(address, instr, AllowUnaligned);
+            set_d_register(Vd, data);
+            break;
+          default:
+            MOZ_CRASH("NYI");
+        }
+        address += 4;
+        if (Rm != 15) {
+          if (Rm == 13) {
+            set_register(Rn, address);
+          } else {
+            set_register(Rn, get_register(Rn) + get_register(Rm));
+          }
+        }
+      } else {
+        MOZ_CRASH();
+      }
+      break;
     case 0xA:
       if (instr->bits(31, 20) == 0xf57) {
         switch (instr->bits(7, 4)) {
           case 1:  // CLREX
             exclusiveMonitorClear();
             break;
           case 5:  // DMB
             AtomicOperations::fenceSeqCst();
diff --git a/js/src/jit/arm/disasm/Disasm-arm.cpp b/js/src/jit/arm/disasm/Disasm-arm.cpp
--- a/js/src/jit/arm/disasm/Disasm-arm.cpp
+++ b/js/src/jit/arm/disasm/Disasm-arm.cpp
@@ -1728,16 +1728,45 @@ void Decoder::DecodeSpecialCondition(Ins
                                     (1 << size) << 3);
         FormatNeonList(Vd, type);
         Print(", ");
         FormatNeonMemory(Rn, align, Rm);
       } else {
         Unknown(instr);
       }
       break;
+    case 9:
+      if (instr->Bits(21, 20) == 0 && instr->Bits(9, 8) == 0) {
+        // vst1
+        int Vd = (instr->Bit(22) << 4) | instr->VdValue();
+        int Rn = instr->VnValue();
+        int size = instr->Bits(11, 10);
+        int index = instr->Bits(7, 5);
+        int align = instr->Bit(4);
+        int Rm = instr->VmValue();
+        out_buffer_pos_ +=
+            SNPrintF(out_buffer_ + out_buffer_pos_, "vst1.%d {d%d[%d]}, ",
+                     (1 << size) << 3, Vd, index);
+        FormatNeonMemory(Rn, align, Rm);
+      } else if (instr->Bits(21, 20) == 2 && instr->Bits(9, 8) == 0) {
+        // vld1
+        int Vd = (instr->Bit(22) << 4) | instr->VdValue();
+        int Rn = instr->VnValue();
+        int size = instr->Bits(11, 10);
+        int index = instr->Bits(7, 5);
+        int align = instr->Bit(4);
+        int Rm = instr->VmValue();
+        out_buffer_pos_ +=
+            SNPrintF(out_buffer_ + out_buffer_pos_, "vld1.%d {d%d[%d]}, ",
+                     (1 << size) << 3, Vd, index);
+        FormatNeonMemory(Rn, align, Rm);
+      } else {
+        Unknown(instr);
+      }
+      break;
     case 0xA:
       if (instr->Bits(22, 20) == 7) {
         const char* option = "?";
         switch (instr->Bits(3, 0)) {
           case 2:
             option = "oshst";
             break;
           case 3:
diff --git a/js/src/wasm/WasmInstance.cpp b/js/src/wasm/WasmInstance.cpp
--- a/js/src/wasm/WasmInstance.cpp
+++ b/js/src/wasm/WasmInstance.cpp
@@ -1475,42 +1475,16 @@ bool Instance::memoryAccessInGuardRegion
     return false;
   }
 
   size_t lastByteOffset = addr - base + (numBytes - 1);
   return lastByteOffset >= memory()->volatileMemoryLength() &&
          lastByteOffset < memoryMappedSize();
 }
 
-bool Instance::memoryAccessInBounds(const uint8_t* addr,
-                                    unsigned numBytes) const {
-  MOZ_ASSERT(numBytes > 0 && numBytes <= sizeof(double));
-
-  if (!metadata().usesMemory()) {
-    return false;
-  }
-
-  uint8_t* base = memoryBase().unwrap(/* comparison */);
-  if (addr < base) {
-    return false;
-  }
-
-  size_t length = memory()->volatileMemoryLength();
-  if (addr >= base + length) {
-    return false;
-  }
-
-  // The pointer points into the memory.  Now check for partial OOB.
-  //
-  // This calculation can't wrap around because the access is small and there
-  // always is a guard page following the memory.
-  size_t lastByteOffset = addr - base + (numBytes - 1);
-  return lastByteOffset < length;
-}
-
 void Instance::tracePrivate(JSTracer* trc) {
   // This method is only called from WasmInstanceObject so the only reason why
   // TraceEdge is called is so that the pointer can be updated during a moving
   // GC.
   MOZ_ASSERT_IF(trc->isMarkingTracer(), gc::IsMarked(trc->runtime(), &object_));
   TraceEdge(trc, &object_, "wasm instance object");
 
   // OK to just do one tier here; though the tiers have different funcImports
diff --git a/js/src/wasm/WasmInstance.h b/js/src/wasm/WasmInstance.h
--- a/js/src/wasm/WasmInstance.h
+++ b/js/src/wasm/WasmInstance.h
@@ -111,17 +111,16 @@ class Instance {
   const Metadata& metadata() const { return code_->metadata(); }
   bool isAsmJS() const { return metadata().isAsmJS(); }
   const SharedTableVector& tables() const { return tables_; }
   SharedMem<uint8_t*> memoryBase() const;
   WasmMemoryObject* memory() const;
   size_t memoryMappedSize() const;
   SharedArrayRawBuffer* sharedMemoryBuffer() const;  // never null
   bool memoryAccessInGuardRegion(const uint8_t* addr, unsigned numBytes) const;
-  bool memoryAccessInBounds(const uint8_t* addr, unsigned numBytes) const;
   const SharedExceptionTagVector& exceptionTags() const {
     return exceptionTags_;
   }
 
   static constexpr size_t offsetOfJSJitArgsRectifier() {
     return offsetof(Instance, jsJitArgsRectifier_);
   }
   static constexpr size_t offsetOfJSJitExceptionHandler() {
diff --git a/js/src/wasm/WasmSignalHandlers.cpp b/js/src/wasm/WasmSignalHandlers.cpp
--- a/js/src/wasm/WasmSignalHandlers.cpp
+++ b/js/src/wasm/WasmSignalHandlers.cpp
@@ -228,38 +228,16 @@ using mozilla::DebugOnly;
 #  define EPC_sig(p) ((p)->thread.__pc)
 #  define RFP_sig(p) ((p)->thread.__fp)
 #  define R31_sig(p) ((p)->thread.__sp)
 #  define RLR_sig(p) ((p)->thread.__lr)
 #else
 #  error "Don't know how to read/write to the thread state via the mcontext_t."
 #endif
 
-// On ARM Linux, including Android, unaligned FP accesses that were not flagged
-// as unaligned will tend to trap (with SIGBUS) and will need to be emulated.
-//
-// We can only perform this emulation if the system header files provide access
-// to the FP registers.  In particular, <sys/user.h> must have definitions of
-// `struct user_vfp` and `struct user_vfp_exc`, as it does on Android.
-//
-// Those definitions are however not present in the headers of every Linux
-// distro - Raspbian is known to be a problem, for example.  However those
-// distros are tier-3 platforms.
-//
-// If you run into compile problems on a tier-3 platform, you can disable the
-// emulation here.
-
-#if defined(__linux__) && defined(__arm__)
-#  define WASM_EMULATE_ARM_UNALIGNED_FP_ACCESS
-#endif
-
-#ifdef WASM_EMULATE_ARM_UNALIGNED_FP_ACCESS
-#  include <sys/user.h>
-#endif
-
 #if defined(ANDROID)
 // Not all versions of the Android NDK define ucontext_t or mcontext_t.
 // Detect this and provide custom but compatible definitions. Note that these
 // follow the GLibc naming convention to access register values from
 // mcontext_t.
 //
 // See: https://chromiumcodereview.appspot.com/10829122/
 // See: http://code.google.com/p/android/issues/detail?id=34784
@@ -480,225 +458,17 @@ struct AutoHandlingTrap {
   }
 
   ~AutoHandlingTrap() {
     MOZ_ASSERT(sAlreadyHandlingTrap.get());
     sAlreadyHandlingTrap.set(false);
   }
 };
 
-#ifdef WASM_EMULATE_ARM_UNALIGNED_FP_ACCESS
-
-// Code to handle SIGBUS for unaligned floating point accesses on 32-bit ARM.
-
-static uintptr_t ReadGPR(CONTEXT* context, uint32_t rn) {
-  switch (rn) {
-    case 0:
-      return context->uc_mcontext.arm_r0;
-    case 1:
-      return context->uc_mcontext.arm_r1;
-    case 2:
-      return context->uc_mcontext.arm_r2;
-    case 3:
-      return context->uc_mcontext.arm_r3;
-    case 4:
-      return context->uc_mcontext.arm_r4;
-    case 5:
-      return context->uc_mcontext.arm_r5;
-    case 6:
-      return context->uc_mcontext.arm_r6;
-    case 7:
-      return context->uc_mcontext.arm_r7;
-    case 8:
-      return context->uc_mcontext.arm_r8;
-    case 9:
-      return context->uc_mcontext.arm_r9;
-    case 10:
-      return context->uc_mcontext.arm_r10;
-    case 11:
-      return context->uc_mcontext.arm_fp;
-    case 12:
-      return context->uc_mcontext.arm_ip;
-    case 13:
-      return context->uc_mcontext.arm_sp;
-    case 14:
-      return context->uc_mcontext.arm_lr;
-    case 15:
-      return context->uc_mcontext.arm_pc;
-    default:
-      MOZ_CRASH();
-  }
-}
-
-// Linux kernel data structures.
-//
-// The vfp_sigframe is a kernel type overlaid on the uc_regspace field of the
-// ucontext_t if the first word of the uc_regspace is VFP_MAGIC.  (user_vfp and
-// user_vfp_exc are defined in sys/user.h and are stable.)
-//
-// VFP_MAGIC appears to have been stable since a commit to Linux on 2010-04-11,
-// when it was changed from being 0x56465001 on ARMv6 and earlier and 0x56465002
-// on ARMv7 and later, to being 0x56465001 on all CPU versions.  This was in
-// Kernel 2.6.34-rc5.
-//
-// My best interpretation of the Android commit history is that Android has had
-// vfp_sigframe and VFP_MAGIC in this form since at least Android 3.4 / 2012;
-// Firefox requires Android 4.0 at least and we're probably safe here.
-
-struct vfp_sigframe {
-  unsigned long magic;
-  unsigned long size;
-  struct user_vfp ufp;
-  struct user_vfp_exc ufp_exc;
-};
-
-#  define VFP_MAGIC 0x56465001
-
-static vfp_sigframe* GetVFPFrame(CONTEXT* context) {
-  if (context->uc_regspace[0] != VFP_MAGIC) {
-    return nullptr;
-  }
-  return (vfp_sigframe*)&context->uc_regspace;
-}
-
-static bool ReadFPR64(CONTEXT* context, uint32_t vd, double* val) {
-  MOZ_ASSERT(vd < 32);
-  vfp_sigframe* frame = GetVFPFrame(context);
-  if (frame) {
-    *val = ((double*)frame->ufp.fpregs)[vd];
-    return true;
-  }
-  return false;
-}
-
-static bool WriteFPR64(CONTEXT* context, uint32_t vd, double val) {
-  MOZ_ASSERT(vd < 32);
-  vfp_sigframe* frame = GetVFPFrame(context);
-  if (frame) {
-    ((double*)frame->ufp.fpregs)[vd] = val;
-    return true;
-  }
-  return false;
-}
-
-static bool ReadFPR32(CONTEXT* context, uint32_t vd, float* val) {
-  MOZ_ASSERT(vd < 32);
-  vfp_sigframe* frame = GetVFPFrame(context);
-  if (frame) {
-    *val = ((float*)frame->ufp.fpregs)[vd];
-    return true;
-  }
-  return false;
-}
-
-static bool WriteFPR32(CONTEXT* context, uint32_t vd, float val) {
-  MOZ_ASSERT(vd < 32);
-  vfp_sigframe* frame = GetVFPFrame(context);
-  if (frame) {
-    ((float*)frame->ufp.fpregs)[vd] = val;
-    return true;
-  }
-  return false;
-}
-
-static bool HandleUnalignedTrap(CONTEXT* context, uint8_t* pc,
-                                Instance* instance) {
-  // ARM only, no Thumb.
-  MOZ_RELEASE_ASSERT(uintptr_t(pc) % 4 == 0);
-
-  // wasmLoadImpl() and wasmStoreImpl() in MacroAssembler-arm.cpp emit plain,
-  // unconditional VLDR and VSTR instructions that do not use the PC as the base
-  // register.
-  uint32_t instr = *(uint32_t*)pc;
-  uint32_t masked = instr & 0x0F300E00;
-  bool isVLDR = masked == 0x0D100A00;
-  bool isVSTR = masked == 0x0D000A00;
-
-  if (!isVLDR && !isVSTR) {
-    // Three obvious cases if we don't get our expected instructions:
-    // - masm is generating other FP access instructions than it should
-    // - we're encountering a device that traps on new kinds of accesses,
-    //   perhaps unaligned integer accesses
-    // - general code generation bugs that lead to SIGBUS
-#  ifdef ANDROID
-    __android_log_print(ANDROID_LOG_ERROR, "WASM", "Bad SIGBUS instr %08x",
-                        instr);
-#  endif
-#  ifdef DEBUG
-    MOZ_CRASH("Unexpected instruction");
-#  endif
-    return false;
-  }
-
-  bool isUnconditional = (instr >> 28) == 0xE;
-  bool isDouble = (instr & 0x00000100) != 0;
-  bool isAdd = (instr & 0x00800000) != 0;
-  uint32_t dBit = (instr >> 22) & 1;
-  uint32_t offs = (instr & 0xFF) << 2;
-  uint32_t rn = (instr >> 16) & 0xF;
-
-  MOZ_RELEASE_ASSERT(isUnconditional);
-  MOZ_RELEASE_ASSERT(rn != 15);
-
-  uint8_t* p = (uint8_t*)ReadGPR(context, rn) + (isAdd ? offs : -offs);
-
-  if (!instance->memoryAccessInBounds(
-          p, isDouble ? sizeof(double) : sizeof(float))) {
-    return false;
-  }
-
-  if (isDouble) {
-    uint32_t vd = ((instr >> 12) & 0xF) | (dBit << 4);
-    double val;
-    if (isVLDR) {
-      memcpy(&val, p, sizeof(val));
-      if (WriteFPR64(context, vd, val)) {
-        SetContextPC(context, pc + 4);
-        return true;
-      }
-    } else {
-      if (ReadFPR64(context, vd, &val)) {
-        memcpy(p, &val, sizeof(val));
-        SetContextPC(context, pc + 4);
-        return true;
-      }
-    }
-  } else {
-    uint32_t vd = ((instr >> 11) & (0xF << 1)) | dBit;
-    float val;
-    if (isVLDR) {
-      memcpy(&val, p, sizeof(val));
-      if (WriteFPR32(context, vd, val)) {
-        SetContextPC(context, pc + 4);
-        return true;
-      }
-    } else {
-      if (ReadFPR32(context, vd, &val)) {
-        memcpy(p, &val, sizeof(val));
-        SetContextPC(context, pc + 4);
-        return true;
-      }
-    }
-  }
-
-#  ifdef DEBUG
-  MOZ_CRASH(
-      "SIGBUS handler could not access FP register, incompatible kernel?");
-#  endif
-  return false;
-}
-#else   // WASM_EMULATE_ARM_UNALIGNED_FP_ACCESS
-static bool HandleUnalignedTrap(CONTEXT* context, uint8_t* pc,
-                                Instance* instance) {
-  return false;
-}
-#endif  // WASM_EMULATE_ARM_UNALIGNED_FP_ACCESS
-
 [[nodiscard]] static bool HandleTrap(CONTEXT* context,
-                                     bool isUnalignedSignal = false,
                                      JSContext* assertCx = nullptr) {
   MOZ_ASSERT(sAlreadyHandlingTrap.get());
 
   uint8_t* pc = ContextToPC(context);
   const CodeSegment* codeSegment = LookupCodeSegment(pc);
   if (!codeSegment || !codeSegment->isModule()) {
     return false;
   }
@@ -717,25 +487,16 @@ static bool HandleUnalignedTrap(CONTEXT*
   // to the caller's Frame which can be in a different Module. In any case,
   // though, the containing JSContext is the same.
 
   auto* frame = reinterpret_cast<Frame*>(ContextToFP(context));
   Instance* instance = GetNearestEffectiveTls(frame)->instance;
   MOZ_RELEASE_ASSERT(&instance->code() == &segment.code() ||
                      trap == Trap::IndirectCallBadSig);
 
-  if (isUnalignedSignal) {
-    if (trap != Trap::OutOfBounds) {
-      return false;
-    }
-    if (HandleUnalignedTrap(context, pc, instance)) {
-      return true;
-    }
-  }
-
   JSContext* cx =
       instance->realm()->runtimeFromAnyThread()->mainContextFromAnyThread();
   MOZ_RELEASE_ASSERT(!assertCx || cx == assertCx);
 
   // JitActivation::startWasmTrap() stores enough register state from the
   // point of the trap to allow stack unwinding or resumption, both of which
   // will call finishWasmTrap().
   jit::JitActivation* activation = cx->activation()->asJit();
@@ -766,17 +527,17 @@ static LONG WINAPI WasmTrapHandler(LPEXC
   AutoHandlingTrap aht;
 
   EXCEPTION_RECORD* record = exception->ExceptionRecord;
   if (record->ExceptionCode != EXCEPTION_ACCESS_VIOLATION &&
       record->ExceptionCode != EXCEPTION_ILLEGAL_INSTRUCTION) {
     return EXCEPTION_CONTINUE_SEARCH;
   }
 
-  if (!HandleTrap(exception->ContextRecord, false, TlsContext.get())) {
+  if (!HandleTrap(exception->ContextRecord, TlsContext.get())) {
     return EXCEPTION_CONTINUE_SEARCH;
   }
 
   return EXCEPTION_CONTINUE_EXECUTION;
 }
 
 #elif defined(XP_DARWIN)
 // On OSX we are forced to use the lower-level Mach exception mechanism instead
@@ -941,17 +702,17 @@ static struct sigaction sPrevSEGVHandler
 static struct sigaction sPrevSIGBUSHandler;
 static struct sigaction sPrevWasmTrapHandler;
 
 static void WasmTrapHandler(int signum, siginfo_t* info, void* context) {
   if (!sAlreadyHandlingTrap.get()) {
     AutoHandlingTrap aht;
     MOZ_RELEASE_ASSERT(signum == SIGSEGV || signum == SIGBUS ||
                        signum == kWasmTrapSignal);
-    if (HandleTrap((CONTEXT*)context, signum == SIGBUS, TlsContext.get())) {
+    if (HandleTrap((CONTEXT*)context, TlsContext.get())) {
       return;
     }
   }
 
   struct sigaction* previousSignal = nullptr;
   switch (signum) {
     case SIGSEGV:
       previousSignal = &sPrevSEGVHandler;
@@ -1214,10 +975,8 @@ bool wasm::HandleIllegalInstruction(cons
     return false;
   }
 
   jit::JitActivation* activation = TlsContext.get()->activation()->asJit();
   activation->startWasmTrap(trap, bytecode.offset(), regs);
   *newPC = segment.trapCode();
   return true;
 }
-
-#undef WASM_EMULATE_ARM_UNALIGNED_FP_ACCESS


